{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "%pip install openai"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "viAuU-VIx7Fn",
        "outputId": "25f1fb48-ae8a-4eb1-9275-fc377f52cbcb"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting openai\n",
            "  Downloading openai-1.12.0-py3-none-any.whl (226 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m226.7/226.7 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai) (1.7.0)\n",
            "Collecting httpx<1,>=0.23.0 (from openai)\n",
            "  Downloading httpx-0.27.0-py3-none-any.whl (75 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.6/75.6 kB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from openai) (2.6.1)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai) (1.3.0)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai) (4.66.2)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.7 in /usr/local/lib/python3.10/dist-packages (from openai) (4.9.0)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (3.6)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (1.2.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (2024.2.2)\n",
            "Collecting httpcore==1.* (from httpx<1,>=0.23.0->openai)\n",
            "  Downloading httpcore-1.0.4-py3-none-any.whl (77 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.8/77.8 kB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting h11<0.15,>=0.13 (from httpcore==1.*->httpx<1,>=0.23.0->openai)\n",
            "  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (0.6.0)\n",
            "Requirement already satisfied: pydantic-core==2.16.2 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (2.16.2)\n",
            "Installing collected packages: h11, httpcore, httpx, openai\n",
            "Successfully installed h11-0.14.0 httpcore-1.0.4 httpx-0.27.0 openai-1.12.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%pip install python-docx"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "73Ny0I7k0d-O",
        "outputId": "4b79500a-fb4d-4311-8233-24dc6b7b25b5"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting python-docx\n",
            "  Downloading python_docx-1.1.0-py3-none-any.whl (239 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/239.6 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━\u001b[0m \u001b[32m194.6/239.6 kB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m239.6/239.6 kB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: lxml>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from python-docx) (4.9.4)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from python-docx) (4.9.0)\n",
            "Installing collected packages: python-docx\n",
            "Successfully installed python-docx-1.1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!apt-get install ffmpeg"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Lu4enRybRYW5",
        "outputId": "e7a13e26-7ecd-4a88-be11-6313b7330020"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "ffmpeg is already the newest version (7:4.4.2-0ubuntu0.22.04.1).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 35 not upgraded.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%pip install pydub"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VQED5uTMRaIm",
        "outputId": "4fc669ed-6231-4e1a-8a09-0f1a8926279e"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pydub\n",
            "  Downloading pydub-0.25.1-py2.py3-none-any.whl (32 kB)\n",
            "Installing collected packages: pydub\n",
            "Successfully installed pydub-0.25.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import openai\n",
        "from getpass import getpass\n",
        "from pydub import AudioSegment\n",
        "import os\n",
        "import openai\n",
        "from openai import OpenAI\n",
        "import time\n",
        "import json\n",
        "from datetime import date\n",
        "import csv\n",
        "\n",
        "# set the key discretely as I want to share this notebook and not leak anything confidential\n",
        "openai.api_key = getpass('Enter your OpenAI API Key: ')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hM1Wu__-0hiM",
        "outputId": "a9efd9d2-da1d-4562-c153-e3bf9ae82a80"
      },
      "execution_count": 5,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Enter your OpenAI API Key: ··········\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Docs are outdated so I need to come up with a newer working version"
      ],
      "metadata": {
        "id": "B43RT3jVLTyX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "client = OpenAI(api_key=openai.api_key)"
      ],
      "metadata": {
        "id": "AmM1UxHARnBs"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def transcribe_audio(file_path):\n",
        "    with open(file_path, 'rb') as audio_file:\n",
        "        transcription = client.audio.transcriptions.create(\n",
        "            model=\"whisper-1\",\n",
        "            file=audio_file)\n",
        "    return transcription.text"
      ],
      "metadata": {
        "id": "3jgNDTB4RqWH"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "today = str(date.today())"
      ],
      "metadata": {
        "id": "nHF5ZWEDRssR"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gpt_model = \"gpt-4-1106-preview\""
      ],
      "metadata": {
        "id": "gbO39OZtSAz7"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "file_path = '/content/audio/AI_Startups_Talk.mp3'"
      ],
      "metadata": {
        "id": "R5QV9PQKSD5L"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "transcription = transcribe_audio(file_path)"
      ],
      "metadata": {
        "id": "Q61NrG-5SScz"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('\\n * Transcription *\\n')\n",
        "print(transcription)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n4FQq2FlSs32",
        "outputId": "50290f15-9f8c-49c0-c560-339a1edda7b1"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " * Transcription *\n",
            "\n",
            "How would you differentiate between an idea that could be a great foundation for a billion-dollar company and an idea that is likely to get run over by GPT-5? Something that's boring might actually be an incredible business, but why is that? Yeah, let's talk about GPT wrappers. Are people worried about giving these data sets to open AI? All these AI agents are passing the Turing test. I mean, this is why I think the chat interface is wrong. You want to do something in AI, like, this is a good place to, like, look into. Big generational companies are getting built as we speak. Great startup ideas just lying on the ground, you'd, like, trip over them. This might actually be, like, a once-in-a-lifetime opportunity, and I think I actually agree. What a time to be alive! Welcome to the very first episode of The Light Cone. I'm Gary, this is Jared, Harj, and Diana, and we're group partners at Y Combinator, and we get to work with some of the best founders in the world. Jared, why are we calling it The Light Cone? Well, in special relativity, the light cone is the path that light takes from a flash of light. You can imagine a flash of light, and it spreads out in a cone shape. And in special relativity, you think about it spreading out in a cone, both in the future, but also in the past. And in this podcast, we are here in the present, but we are going to talk about both the past and future of technology. So that's how we came up with the name. And one of the things that we're all seeing is the encroachment of AI into almost every piece of society at this point. You know, every business transaction, every thing that we sort of use with computers, suddenly a new burst of technology is sort of entering everything we're doing. And we're seeing it in the startups that we're funding, which is why we're so excited about it. I think, you know, what's the percentage of companies you've backed right now that have large language models? I think for summer 23, it was close to 50% of the batch. And it's pretty interesting. Like, I think a lot of people like see that number and they think, oh, YC must have funded so many AI companies because we have this thesis about AI. And like, it's just easier to get into YC if you're an AI company, because we just like love funding AI companies. And it's funny to us because we know how that's not true. And yet that's probably what like 90, that's probably how 90 plus percent of people actually think YC works. How does it actually work? Should we tell people like how it actually works? Actually, it's interesting. The smart founders apply to us with what they want to work on. And we fund the smart founders, like irrespective of what they want to work on actually. And exactly. And so the fact that half the batch is working on AI says something much more interesting than just the YC partners think AI is cool. It's an emergent phenomenon of what the smart founders want to work on right now. It's like, where do they think there's the high beta to build the largest company? And I think the most ambitious and smartest founders are going after this because it's definitely, I think the exciting thing about right now with AI, I think it's like real. There's been a lot of ways for AI and multiple AI winters. But this one, actually, GPT 3.5 and then 4 blew out of the water a lot of tasks. And it impressed a lot of smart people. When a lot of smart people start paying attention and building in this current idea maze, I think big generational companies are getting built as we speak. One thing I'm seeing that's interesting is I feel like a lot, a lot more founders are dropping out of college to start working on AI. Because there's a FOMO. Yeah, there's like an actual like, and usually it's so funny. My interview question is always like, what's the rush? Like, why do you want to drop out of college? Like, why don't you just like graduate? Because it makes a lot more sense to graduate and then do a startup. And the reply is usually like, well, like, this might actually be like a once in a lifetime opportunity. And I think I actually agree. And the other cool thing is that this is an opportunity where college students are particularly well, like young founders are particularly well positioned to work in it. Because nobody has, like, there's no one walking around with like four years of LLM experience. So like everyone is starting from the same playing field. And so if you can learn fast, you're going to be at the same level as everybody else. And you know, one, an area I've seen that come to play is like developer tools for prompt engineering. I mean, seeing like these sorts of tools are getting uptake. It's like the ability to like chain together different prompts and test your prompts and see like the second order effects. And actually a lot of college students are the people who are just like playing around with like prompting models and seeing what comes out. And it's a really easy startup idea for them to like just build the tools that they want. And like the tools that they want are literally setting like the standard for what every developer should want. Like I know a lot of the headlines are all around like AGI and all of the fancy stuff. And then the really cool demos of like multimodal AI, like AI generated video and this kind of stuff. The stuff that I've seen in the batches that are actually taking off is a little bit more mundane. Like it's, I mean, I probably say a lot of it's sort of like workflow automation. Like it's finding things where there was like a human doing some repetitive tasks, usually involved like searching for things or filling out forms. And then using like LLMs to replace that. It feels very obvious to us, the people who work at YC, that this is an amazing opportunity. There's so many jobs in the world that are basically very mundane information processing. Typically stuff that's like hidden in some back office somewhere where there's somebody who's just like reading stuff and summarizing it, re-entering it from one system into a different system and like a slightly different format. And it's such a perfect fit for LLMs. LLMs are like perfect for this job. And yet we actually don't get that many applications for people working on this. And there's a lot of founders out there who are searching for a great idea. So if you're out there and you're looking for a great startup idea and you want to do something in AI, like this is a good place to like look into. I'll give you an example. So last batch had a company I worked with called Sweet Spot and we funded them. The idea was something about like food ordering from food trucks, something like random. And they pivoted immediately looking for a new idea. And the idea they found was using LLMs to automate searching for government contracts to bid on and submitting the proposal. That sounds so boring. What could be more boring than searching through like a list of all the government contracts? You know how they found it is they're exploring startup ideas and then they realized one of their friends, his job was to work for one of these like government contractors and his whole day was just spent like refreshing this government website. To like find things and then submitting proposals. They're like, what? Like, that's like exactly that. That's so boring. Like, wouldn't you like a tool that did this for you? Yeah, and they launched and like pretty much straight out of the gate got like a pretty decent amount of traction because they're like opening up the people who would actually do it. Like it becomes easier to like find government contracts to bid on when it's all automated away and like software does it for you. Obviously, we all know that something that's boring is actually kind of awesome. But why is that? That's like, you know, just off the bat, you know, we have a sense that something that's boring might actually be an incredible business. There's an old PG essay where he talks about this and he says, he quotes a phrase, where there's muck, there's brass. It's like, it's almost like old English. You want to explain it, Harj? Just means that you can find treasure in surprising places. And I think the cool thing is you have to go deep and vertical and solve a very concrete problem. Like some of the problems with, let's maybe talk about AI tar pits. What a tar pit idea is, is it's an idea that from the outside looks really shiny and attractive. It looks like a great startup idea. And so lots of founders go and they start working on it. And then you realize once you're in it, that it's actually not a good startup idea. But by the time you're there, you're like stuck in it. And so it just attracts founder after founder, and they just get stuck in the tar pit idea. And we see this a lot at YC because we see all these applications. And so it's really obvious to us when like 500 people apply to a YC batch for the same idea, but they don't know that 499 other founders are also stuck in the same tar pit. What's tricky, I think, about tar pit ideas for AI is like, we know something's a tar pit idea in hindsight, once like enough people have been stuck in it. So with AI, it's so new, we don't know yet. I have a couple that I'm actually keen to get your thoughts on. A very common one is AI co-pilot. So it's like, hey, I'm going to make it easy for people to build an AI co-pilot for their product or service. It's this really unusual type of phenomenon where there's so much interest from potential customers to want a co-pilot that it's actually quite easy to start getting inbound leads if you pitch this. And it's even easy to get people to pay you money upfront. But what's really hard is to get them to actually use the co-pilot because they don't actually know what they want it for. They've just heard that AI co-pilots might be changing the future of software. So we should have an AI co-pilot, but they don't actually know what their customers will use it for. I think for me, and maybe I just have a mental block around chat interfaces, but I've never been that big a fan of chat because it puts so much of the emphasis on the user knowing how to speak to a computer. And, you know, well, in the next five or 10 years, I think we will get far more used to using it that way. I think the low-hanging fruit right now is just using the large language model to actually do the sort of knowledge work that a human being could do and then package it into the UI that, you know, whether it's a mobile app or a web app that is just familiar, like sort of what people use to do their work right now. And it's, you know, basically the LLM is better used as sort of this, like, I mean, it's almost like, you know, this thing that's sprinkled in that, you know, the software suddenly does something really powerful, but you don't have to change the way you would want to use the software as it is. It's sort of like an example of a phenomenon that, like, I think we have seen in the past when, like, some technology gets really hot and all of a sudden, like, all these companies are, like, they're being asked by people, like, what's our AI strategy? They're like, oh, well, we better get an AI strategy. Or, like, with crypto, there was like, oh, everybody needed a blockchain strategy. And even before that, it was like everybody needed a mobile strategy. For a moment in time, it's, like, easy to sell them something that, like, placates their desire to check some box. But in the end, you've got to actually make it successful for them. Like, otherwise, it's not going to stick. I agree. And so, like, perhaps with this AI copilot thing, like, maybe it's too early to call. Like, perhaps they actually will find product market fit, maybe with something that's not a chatbot UI. Like, they'll, like, keep iterating on the UI until they find something that's an AI copilot people actually want. Or maybe it's just going to, like, fizzle. It just, like, turns out most people don't need an AI copilot. Some of the advice I've been giving those specific companies is another old PG essay about if you're trying to sell technology to someone and they're not buying, like, see if you can just build a competitor. And so it's like, hey, if you're trying to sell, like, a fintech company a copilot and they're not buying it, well, like, if you are convinced they should have a copilot, like, why don't you just, like, build the company with the copilot as the main experience and see if you can outcompete them or not? I like that. I like that. I think getting people to focus on the use case. I think the problem is the whole thing with kind of the gold rush. People selling more the shovels and the tools. And even then, in this case, it is a bit of that. But a lot of people aren't digging gold yet. Like, the reality is this is such a new technology. And even the end applications that apply AI, the reality is they're so early, they don't have product market fit. So it's sort of a bit of the blind leading the blind in here. It's like, what? Do I even know what the pattern is for copilot? I mean, it sounds cool just to join the cool kid club of we're doing AI and we're going to checkmark. So I think that's the danger for a lot of these startups. It's like, it seems that they're getting traction, as you mentioned, but then when we poke them closer, is anyone actually using you? What are the actual use case? And then the founders come back and they start a blanket. It's like, oh, but look at all the signup. Look at the revenue. But then they're not really using your product. I mean, we're seeing even the second order effects, right? So a bunch of us are funding dev tools companies that sell to AI companies and they're selling tooling. But then they might sell an enterprise contract to someone who also upstream has a Fortune 100 that said that they'd pay $100,000 a year for that contract. And then six to nine months later that Fortune 100 went back to the incumbent, some other leading IBM, Salesforce, something like that, because they ended up adding large language model technology to what they were doing. And people just switched back. And suddenly the dev tool company suddenly realizes, oh, I had five contracts, but three of them went away because my customer actually lost their customer. So it's actually remarkable how fast this is evolving right now in 2024. A specific type of idea I'm curious to get thoughts on here as well is offering fine tuning open source models as a service broadly. That's a very popular idea, I think, over the course of 2023. Here's what I've seen. Why do people want, why is there any demand for a fine tuned open source model at all? It tends to be initially, I think the big driver was cost, like open AI, like chat GPT was expensive and people wanted a cheaper version of it. And so I think it was very easy to get customers with the pitch of, hey, we can fine tune an open source model and it's just going to be much cheaper. What I think a bunch of the companies in the space are seeing is that that's not enough to keep the customers, especially because like open AI, like the cost of all of the model is just going down. And that's going to keep happening with the open AI has a plan for all of those. So there's something more that all these fine tuning companies need to do. It has to be better, not just cheaper. I think where it's exactly that where I think is having more legs is when these companies need to customize it to private data sets. So you have the open general big foundation model, but then you have to tune it up to specific data sets that, for example, healthcare or fintech can't give out and they don't have the team of experts to do it. So I think the one company that I think Brad worked with was Credel that kind of was doing that. What are you seeing about like the concern around data privacy is another big reason. Like, are you seeing that as being enough? Like are people worried about giving these data sets to open AI? It's really interesting. It's really interesting. I mean, whenever you have something so new like this, it's actually sort of resets the clock on the competitive landscape again. So, you know, you almost can expect all the same things will happen again. You know, just as 10, 15 years ago, cloud was brand new. And then you had cloud cybersecurity and cloud strike and all these companies sort of come out. You know, we're seeing the first wave of cybersecurity companies, you know, like prompt armor. So they sort of wrap your API calls. And what they actually have figured out is that for a lot of large language models, if you do any sort of fine tuning or training with private data, you can actually just speak to the model and get it to spit out your private data again. And they have a solution that stops it. So it's so interesting because, you know, it's entirely possible. You know, they're basically creating a new industry again of cybersecurity for LLMs sort of in the same way that cloud opened up that space and created cybersecurity for the cloud. Yeah, I definitely think that whole world of controlling within an enterprise in particular, like controlling who has access to like, which LLM has access to like what data and who has permissions is like a really ripe space for building interesting software. I think the other exciting area that a lot of dev tools are getting built is getting more, this is like a step further fine tuning, but more purpose trained models that are smaller. So take, for instance, LLAMA and getting those to run locally in machines for inference. And when you customize them, train on a specific domain and target data is going to perform better than the general model. The general model was kind of trained on all of the human language for all of the tasks. But if you wanted to build like the best, let's say, language model for parsing SQL queries, you would then parse very specifically just the set for SQL query. And I think some of those that are interesting companies that we fund is like LLAMA that you funded that's trying to make the development process for running all of these locally a lot faster. And I think we're also funding some of these that are custom for coding. The thing that was surprised learning from some of the startups that are building coder type of copilots, which I think is a use case that's working out making a lot of the workflow for programming a lot faster. It's kind of like autocomplete and copilot type of thing. They're training on older models of GPT. They don't even need the newest one. And then I asked like, why is that? And even for like one of the companies who funded last batch, Metalware for hardware, they're not using the state of the art model. Like the older GPT, I forget which one was like the older 2.5 or 3 was sufficient and actually creating good enough results. Because the vocabulary for specific domain for hardware or software is a lot smaller than the human language. So this is other world where the open model that's customized, I think it's going to win and compete versus the big one for specific domains. So lots of companies with this. Yeah, that's what Toby Lutke from Shopify actually still dabbles with the stuff. I think he actually built the internal copilot for Shopify. And what he was saying is the best way to use whatever GPT-4 or the latest closed source models that are most expensive and have the most parameters. Just think of it as a prototyping tool. Anything you do with those prompts, you can get your own model to do with a little bit more training. It's kind of like when people build hardware, you have the analogy of prototyping with FPGAs, which are very expensive, right? And then when you have the right architecture for hardware, then you do the circuit path and actually do the custom SOC. So right now for some of these tasks, the large language model is sort of like your FPGA, whatever GPT-4. And then when you customize it, you do like a super efficient one coding path for, I don't know, Shopify for coding assistance and hardware, software, et cetera, that becomes your SOC that you train and customize, which is cool. I think that pattern is emerging. So as I hear you talk about that, Diana, what's interesting, I just think it's just like so many different startups that could be built. It just feels like we've never had this moment, or at least I didn't feel like I've never experienced a moment where there's just so many potential startup ideas to be built all at once. Yeah, there absolutely hasn't. And we definitely saw this in the last batch with all the pivoting companies. Oh, yes. People don't always realize this, but like many of the companies that get into YC, within a month after we fund them, they're looking for a new idea because the old thing didn't work or they lost interest in it or something. And it's normally not actually that easy to find a great startup idea for a team to work on. But man, was it easy last summer. Oh my gosh. It was just like great startup ideas just lying on the ground. You'd like trip over them. Yeah. That was the best. I think you actually had a tweet about it. Went pretty viral that talked about this is the batch, the batch ever in your whole career working at YC where founders got to good ideas the fastest ever. And hard has been here even longer. Yeah, no, it definitely feels unique. I've never had so many successful pivots. Yeah. And Gary, to your point about the chat GPT wrapper, I feel like that meme really came out just about a year ago. Yeah, let's talk about GPT wrappers. I feel like the first sort of group of ideas I saw in the batch were all sort of generative AI ideas built on top of chat GPT. So it's stuff like, Hey, like automate your marketing copy or automate like your creative content or something like that. And that term got thrown out. Oh, these things are all just like wrappers on top of chat GPT. And open AI is going to like take all of that. You're just going to build all of these things and they were going to release their app store. And like, it's just going to take all the value and these things will die. All of this, all of SAS software is just MySQL. Exactly. I think this is a great analogy. You can think about any SAS product as basically a database wrapper. Like you could imagine like negging any SAS product is like the first version of a SAS product. It's basically just a CRUD app. And just like you took like MySQL and then you like built like a website on top of it. And I think people are going to look back on this term GPT, GPT wrapper, like similarly how we think of like, how we would look at the term database wrapper, which just seems like silly. I mean, this is why I think the chat interface is wrong. Like I actually think there is value accrued to really great UX, like good copy, good, you know, interaction design, information hierarchy, you know, being able to approach a product and say like, this is the job to be done. And for users to come in and just sort of naturally understand what to do. Like there is a craft to building software that is timeless and that sort of transcends whether or not you're using a large language model. And so, you know, that I think is what I mean by, you know, these things are not, you know, SAS software is not a MySQL wrapper. Well, here'd be a question I'd be interested in everyone's thoughts on. Suppose you're a new founder and you really want to build a big company and you want to do something on top of LM's. How would you differentiate between an idea that could be a great foundation for a billion dollar company and an idea that is likely to get run over by GPT-5 and is probably like not a good starting point? I think if a founder is working on something too general and not solving a specific need for a user, they can actually go talk to another use case. So I worry about the ones that are too generic and building, going after some kind of abstract. We will solve all the things. Yeah. If it's like, hey, like throw your data in here and we'll do like automations on top of it. Like for everything, that's probably hard to compete with whatever one of the foundation models might offer. But if it's like, hey, give us like your sales log data and we'll spit back like suggested next actions for sales people to make them better at sales. That's probably going to work better. Or give us all your compliance checklist to pass HIPAA compliance and process that. It's like that's very specific and lots of business logic. Or give us all of your data for processing government forms, right? Yeah. So it's a lot of custom business logic. So the same thing with the SaaS era. A lot of the applications and how you build applications in there, there's always the separation of business logic. And they're creating a lot of architectures for these apps. And a lot of the value of the company is accrued on that business logic that is so custom per company. And there's a whole pattern of programming patterns on how people separate those. Yeah, as this all goes multimodal, this is going to get really interesting. So early days. But yeah, we've seen companies work on voice AI apps to be like a sales rep. And I think it's an interesting example of the kinds of ideas that might be possible now with AI is where you take something like a Salesforce and you try and reimagine like what would Salesforce do if it were started today with all the power of AI? Well, it almost certainly do more than just be like a CRM, right? Like it would find who your leads might be. Maybe now it can make the calls for you. It could set them up. Maybe it goes all the way to start implementing the first version of the product for them. I think it's just like the scope of software you can build with AI now is so big. I think that's another good way to find ideas. Look at software today and reimagine it with the power of AI today. We should fund a number of companies that effectively are AI voice agents for small businesses because they receive, I don't know, if you're like a flower shop or AC repairman in the middle of the US, there's a lot of calls for you to schedule and you don't have a lot of stuff automated. And there's these YC companies that are using, they're building these AI voice agents to basically be their receptionist. I know one of our partners, Paul Buchheit, is quite worried about this, actually. He's worried about there's going to be a world of just sort of like all these AI agents that are out trying to do malicious things and that we're going to need our own good defensive AI agents out there making sure we don't get scammed out of all of our money. I mean, this is actually why I'm so an advocate for open source AI because these things are sort of real considerations. Can you imagine there only being one hyper dominant AGI and it's totally closed source, it's owned by one company and it's only available to the highest bidder. And imagine you being someone who just had to go to the doctor and on the other end of it is some health insurance company that bought access and blocked it out from everyone else. And you getting on the phone, you're not able to sort of navigate or go against the sort of impenetrable AGI that is able to sort of get around anything that your side might throw at it. We actually want some form of actually equity at the AI level. We actually want not merely the biggest companies to own the most capable AIs. We want all consumers to be able to have from the bottom up the same access to that same technology. And that's the best insurance against tyranny. And certainly that's actually what a lot of also not just founders, but smartest researchers who are really at the cutting edge. They went to near Ips this past December, which was incredible to see the energy in there. The conference has grown so much. I think it's like over 10,000 attendees. There were 3,000 papers, more than 3,000 papers accepted. And I think back in 2017, there was only around 600 papers. When I went back in 2010, it was just in a ski lodge and maybe like 100 papers. It's crazy. The kind of exponential growth. And one of the big topics of interest was a lot around AI ethics and regulation and how do we measure that. So that was interesting. But the thing that's different about typically that was interesting in this conference is the amount of interest from researchers wanting to start companies too. One interesting data point is a lot of this era with GPT came about from one foundation paper is all attention you can need. It was this paper that got launched in near Ips back in 2017. It was a team at Google who was trying to figure out how to make machine translation between languages more cheap. Because English translation to any language is actually pretty good. But if you wanted to do, I don't know, German to Japanese, there's not enough data. So they figured out this way to compress data, which became the transformer models for GPT. And it was groundbreaking. And this is the foundation for LLMs. That paper came out in 2017. And the fun fact, I was just looking this up. Out of all those authors, eight authors, seven of them started different companies. And all of the companies in total, they're worth valuation more than $6 billion. And now people are seeing, oh, these industry pioneers did this. And it's creating this new crop of, I think, founders that I don't think would have started. Because I talked to a lot of AI researchers. And I don't think they wanted to be founders. And I got a lot of this question. How can I turn my paper into a company? Which I think is cool. Because this is going back to the root of YCF funding hardcore technical founders. And I think it's cool to see that energy there. So when we went and hosted our event, I didn't plan. And it was like 3x oversubscribed. Nice. Standing room only, huh? Yeah. Yeah. That sounds like really the new homebrew computer club. So NeurIPS in December. Yeah. We got to mark it on the calendar. Welcome back. Yep. Diana, I love your point about how this is returning YC to its roots. It definitely felt that way last summer. Because when YC got started, the internet was really new. And the people who were building stuff on the internet were mostly technologists. It was actually pretty hard to build websites back then. And pretty hard to build good software. And as software and building websites got commoditized, a lot more people came into the space. And this is a cool reversion back to the origins, where the people who are building the most interesting stuff are mostly really hardcore researchers and technologists. Because there's actually real new technology being invented. It's not just innovating on business models, but commoditized technology. And again, just like every great technology, it's being dismissed, right? So going back to the chat-GBT-rapper meme. Again, I actually think that was great for YC. Because it meant we only got the people who could tune that out. And we're just like, hey, either I'm just so interested in this technology, I don't care what the memes are, or I'm just too busy building it to pay attention to the meme on Twitter, which is also great. But I feel like this has always been the case, right? Like Homebrew Computer Club, PCs are dismissed as toys. The internet is dismissed as a toy. All of these things. So it feels like that moment again. Yeah, there is a classic essay that I love that I saw off Hacker News. Do you guys remember this? It's geeks, mops, and sociopaths in subculture evolution. And I think that actually is the one thing that's quite durable and keeps returning, right? It's always the geeks who are going to be into the tech no matter what. They're on the cutting edge. I always think of Steve Wozniak talking about, we started Apple Computer with no idea that it would ever be a company. Like we just wanted computers for ourselves and our friends. And so at some point, the sociopaths come along and they start sort of monetizing the people who come to the scene. And then the cycle returns and repeats. So that's why I like being at the beginning of a new cycle. And clearly AI is exactly that. So don't count it out. Don't write it off. It's one of the most interesting things that is happening out there. But there are clearly things to be careful of. Like don't be attracted to the new shiny thing. Instead, look for the muck because where there's muck, there's brass. So that might be a great place to call it for the very first episode of The Light Cone. We'll see you next time.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# now I will save the transcription into a .txt file\n",
        "with open('transcription.txt', 'w') as f:\n",
        "    f.write(transcription)"
      ],
      "metadata": {
        "id": "huzOa0p5S1pb"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Awesome! I've successfully managed to transcribe the AI startups talk using whisper and then save it to a .txt file. Now it's time do some cool analysis."
      ],
      "metadata": {
        "id": "v-WTmTCQTDMR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def abstract_summary_extraction(transcription):\n",
        "    response = client.chat.completions.create(\n",
        "        model=gpt_model,\n",
        "        temperature=0,\n",
        "        messages=[\n",
        "            {\n",
        "                \"role\": \"system\",\n",
        "                \"content\": \"You are a highly skilled AI trained in language comprehension and summarization. I would like you to read the following transcription of a meeting and summarize it into a concise abstract paragraph. Aim to retain the most important points, providing a coherent and readable summary that could help a person understand the main points of the discussion without needing to read the entire text. Please avoid unnecessary details or tangential points.\"\n",
        "            },\n",
        "            {\n",
        "                \"role\": \"user\",\n",
        "                \"content\": transcription\n",
        "            }\n",
        "        ]\n",
        "    )\n",
        "    return response.choices[0].message.content"
      ],
      "metadata": {
        "id": "LwU41l4yepNf"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "abstract = abstract_summary_extraction(transcription)"
      ],
      "metadata": {
        "id": "bNmSGKM_er_E"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('\\n * Abstract *\\n')\n",
        "print(abstract)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R5GpmX7Re0q5",
        "outputId": "9bc9fb99-3978-48af-f1d0-62ccd41e06cd"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " * Abstract *\n",
            "\n",
            "In the inaugural episode of The Light Cone podcast, Y Combinator partners Gary, Jared, Harj, and Diana discuss the burgeoning impact of AI on startups and society. They explore the significance of AI in current startup trends, noting that nearly half of YC's Summer 2023 batch involves large language models (LLMs). The conversation highlights the importance of focusing on specific, often mundane, business problems that AI can address, rather than chasing after broad, shiny applications that may become \"tar pits\" for founders. They emphasize the potential for AI to automate repetitive tasks, such as government contract bidding, and the opportunity for young founders to enter the AI field due to the level playing field created by the novelty of the technology.\n",
            "\n",
            "The group also touches on the ethical considerations of AI, the importance of open-source models for democratizing access, and the potential for AI to revolutionize existing software products. They caution against generic AI solutions that lack a clear use case and stress the value of good UX and targeted business logic. The episode concludes with a reflection on the cyclical nature of technology adoption and the enduring role of technologists in driving innovation.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def key_points_extraction(transcription):\n",
        "    response = client.chat.completions.create(\n",
        "        model=gpt_model,\n",
        "        temperature=0,\n",
        "        messages=[\n",
        "            {\n",
        "                \"role\": \"system\",\n",
        "                \"content\": \"You are a proficient AI with a specialty in distilling information into key points. Based on the following text, identify and list the main points that were discussed or brought up. These should be the most important ideas, findings, or topics that are crucial to the essence of the discussion. Your goal is to provide a list that someone could read to quickly understand what was talked about.\"\n",
        "            },\n",
        "            {\n",
        "                \"role\": \"user\",\n",
        "                \"content\": transcription\n",
        "            }\n",
        "        ]\n",
        "    )\n",
        "    response = response.choices[0].message.content\n",
        "    return response"
      ],
      "metadata": {
        "id": "MCOEePqUfQ6T"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "key_points = key_points_extraction(transcription)"
      ],
      "metadata": {
        "id": "chiJFPIkfSpS"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('\\n * Key Points *\\n')\n",
        "print(key_points)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C85NaB7-fXHx",
        "outputId": "36afd3b3-7ddd-43b5-9aba-735e892e243b"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " * Key Points *\n",
            "\n",
            "1. The podcast \"The Light Cone\" is hosted by Y Combinator partners who discuss technology's past and future.\n",
            "2. AI is increasingly integrated into society and startups, with about 50% of Y Combinator's Summer 2023 batch involving large language models (LLMs).\n",
            "3. The surge in AI startups is driven by smart founders who see the potential to build large, generational companies.\n",
            "4. There's a trend of founders dropping out of college to pursue AI opportunities, which are seen as once-in-a-lifetime.\n",
            "5. AI is creating opportunities for workflow automation by replacing repetitive human tasks, particularly in information processing.\n",
            "6. There's a perception that Y Combinator prefers AI companies, but in reality, they fund smart founders regardless of their focus area.\n",
            "7. The podcast discusses the potential for AI to automate mundane tasks, such as searching for government contracts, which can be lucrative despite seeming boring.\n",
            "8. The term \"AI tar pits\" refers to startup ideas that seem attractive but are actually not viable, trapping many founders.\n",
            "9. There's a debate about the effectiveness of AI co-pilots and chat interfaces, with some skepticism about their current utility.\n",
            "10. The discussion covers the importance of focusing on specific use cases and business logic to create successful AI startups.\n",
            "11. There's a concern about data privacy and the need for cybersecurity in the context of AI.\n",
            "12. The podcast touches on the trend of fine-tuning open-source models for specific domains, which can be more efficient than using the latest general models.\n",
            "13. The episode concludes with a discussion on the potential for AI to reimagine existing software and the importance of finding startup ideas that solve specific user needs.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def action_item_extraction(transcription):\n",
        "    response = client.chat.completions.create(\n",
        "        model=gpt_model,\n",
        "        temperature=0,\n",
        "        messages=[\n",
        "            {\n",
        "                \"role\": \"system\",\n",
        "                \"content\": \"You are an AI expert in analyzing conversations and extracting action items. Please review the text and identify any tasks, assignments, or actions that were agreed upon or mentioned as needing to be done. These could be tasks assigned to specific individuals, or general actions that the group has decided to take. Please list these action items clearly and concisely.\"\n",
        "            },\n",
        "            {\n",
        "                \"role\": \"user\",\n",
        "                \"content\": transcription\n",
        "            }\n",
        "        ]\n",
        "    )\n",
        "    response = response.choices[0].message.content\n",
        "    return response\n"
      ],
      "metadata": {
        "id": "yoM6L8cCfjpT"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "action_items = action_item_extraction(transcription)"
      ],
      "metadata": {
        "id": "p8c3yeeXggnj"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('\\n * Action Items *\\n')\n",
        "print(action_items)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "697ZVYqjgkxy",
        "outputId": "1765130c-70b5-4555-c5c2-c9adcaf85fcc"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " * Action Items *\n",
            "\n",
            "Based on the conversation, here are the action items and tasks that were mentioned:\n",
            "\n",
            "1. Founders should look into AI applications for mundane information processing jobs, particularly those involving repetitive tasks like searching for things or filling out forms.\n",
            "\n",
            "2. Founders should consider the potential of AI in automating the search for government contracts and the submission of proposals, as exemplified by the company Sweet Spot.\n",
            "\n",
            "3. Founders should explore the development of developer tools for prompt engineering, especially tools that can chain together different prompts and test them.\n",
            "\n",
            "4. Founders should investigate the creation of cybersecurity solutions for large language models (LLMs), such as prompt armor, which prevents the model from regurgitating private data.\n",
            "\n",
            "5. Founders should consider building AI voice agents for small businesses to act as virtual receptionists.\n",
            "\n",
            "6. Founders should reimagine existing software with the power of AI, considering how AI could expand the scope of what software can do.\n",
            "\n",
            "7. Founders should focus on creating fine-tuned, purpose-trained models that are smaller and more efficient for specific domains, rather than relying solely on general, large foundation models.\n",
            "\n",
            "8. Founders should be cautious of \"tar pit\" ideas that seem attractive but may not lead to successful startups.\n",
            "\n",
            "9. Founders should differentiate between ideas that could be the foundation for a billion-dollar company and those that might be overtaken by future AI developments like GPT-5.\n",
            "\n",
            "10. Founders should consider the importance of good UX and interaction design in their products, beyond just the underlying AI technology.\n",
            "\n",
            "11. Founders should be aware of the potential for AI to be used maliciously and consider building defensive AI agents.\n",
            "\n",
            "12. Founders and researchers should consider turning their papers and research into startup companies, particularly in the field of AI.\n",
            "\n",
            "13. Attendees and organizers should mark NeurIPS (a major AI conference) on their calendars for future participation and networking.\n",
            "\n",
            "14. Founders should seek to build startups that solve specific user needs with custom business logic, rather than generic solutions.\n",
            "\n",
            "15. Founders should be mindful of the potential for commoditization in the AI space and focus on innovation in technology rather than just business models.\n",
            "\n",
            "These action items are directed at founders and entrepreneurs interested in leveraging AI technology to build startups and create new products or services.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def participant_list(transcription):\n",
        "    response = client.chat.completions.create(\n",
        "        model=gpt_model,\n",
        "        temperature=0,\n",
        "        messages=[\n",
        "            {\n",
        "                \"role\": \"system\",\n",
        "                \"content\": \"You are an AI expert in analyzing conversations and extracting names and roles of the people speaking. Please review the text and identify each person named in the discussions, their title or role, and any other personal information they provide such as location.  Be sure to review the entire conversation and include new people named later in the meeting.  The meeting may be a company earnings conference call with analysts; if this is the case be sure to include the analysts asking questions later in the call.  Please list all of the the names and their related information clearly and concisely.  If there are clear groups of people, such as customer and supplier, group them accordingly\"\n",
        "            },\n",
        "            {\n",
        "                \"role\": \"user\",\n",
        "                \"content\": transcription\n",
        "            }\n",
        "        ]\n",
        "    )\n",
        "    response = response.choices[0].message.content\n",
        "    return response"
      ],
      "metadata": {
        "id": "jVQEnl4OgyNp"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "participants = participant_list(transcription)"
      ],
      "metadata": {
        "id": "1Jxo9PsCg1Iw"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('\\n * Participants *\\n')\n",
        "print(participants)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y-GB7Ezhg4or",
        "outputId": "b97930ad-9c48-4411-f05a-1df35a643719"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " * Participants *\n",
            "\n",
            "The conversation involves four individuals who are group partners at Y Combinator. Their names and roles are as follows:\n",
            "\n",
            "1. Gary - Group Partner at Y Combinator\n",
            "2. Jared - Group Partner at Y Combinator\n",
            "3. Harj - Group Partner at Y Combinator\n",
            "4. Diana - Group Partner at Y Combinator\n",
            "\n",
            "No specific personal information such as location is provided for any of the individuals in the conversation. The discussion revolves around the impact of AI on startups, the emergence of AI in various sectors, and the potential for new companies in the field of AI. They also discuss the concept of \"GPT wrappers\" and the importance of focusing on specific use cases rather than general applications to avoid being outcompeted by more advanced AI models in the future.\n",
            "\n",
            "Additionally, they mention a company called Sweet Spot, which pivoted to using LLMs for automating the search for government contracts, and another company called Credel, which specializes in customizing AI models to private datasets. They also reference Toby Lutke from Shopify, who is involved in building internal AI tools, and Paul Buchheit, another partner at Y Combinator, who has concerns about AI agents.\n",
            "\n",
            "Furthermore, they discuss the NeurIPS conference, where AI researchers show interest in starting companies, and mention a foundational paper titled \"Attention Is All You Need,\" whose authors have started companies worth over $6 billion in total valuation.\n",
            "\n",
            "Lastly, they mention a company called LLAMA, which is working on making the development process for running AI models locally faster, and another company called Metalware, which is focused on hardware.\n",
            "\n",
            "The conversation concludes with the first episode of \"The Light Cone,\" a podcast by the Y Combinator partners. No analysts or other individuals are mentioned in the conversation.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def sentiment_analysis(transcription):\n",
        "    response = client.chat.completions.create(\n",
        "        model=gpt_model,\n",
        "        temperature=0,\n",
        "        messages=[\n",
        "            {\n",
        "                \"role\": \"system\",\n",
        "                \"content\": \"As an AI with expertise in language and emotion analysis, your task is to analyze the sentiment of the following text. Please consider the overall tone of the discussion, the emotion conveyed by the language used, and the context in which words and phrases are used. Indicate whether the sentiment is generally positive, negative, or neutral, and provide brief explanations for your analysis where possible.\"\n",
        "            },\n",
        "            {\n",
        "                \"role\": \"user\",\n",
        "                \"content\": transcription\n",
        "            }\n",
        "        ]\n",
        "    )\n",
        "    response = response.choices[0].message.content\n",
        "    return response"
      ],
      "metadata": {
        "id": "LL7ErBqahBnq"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sentiment = sentiment_analysis(transcription)"
      ],
      "metadata": {
        "id": "8UUjNeWOhFN2"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('\\n * Sentiment *\\n')\n",
        "print(sentiment)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7K8RPERLhI2X",
        "outputId": "0f820d32-f670-43c9-e00a-91f4fabbf6c5"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " * Sentiment *\n",
            "\n",
            "The sentiment of the text is generally positive, with a strong sense of excitement and optimism about the potential of AI and startup opportunities. The speakers convey enthusiasm about the transformative impact of AI on various industries and the emergence of new companies. They discuss the potential for once-in-a-lifetime opportunities and the sense that great startup ideas are abundant and accessible. The tone is one of encouragement for founders to explore AI and capitalize on the current technological advancements.\n",
            "\n",
            "The language used includes phrases like \"what a time to be alive,\" \"incredible business,\" \"once-in-a-lifetime opportunity,\" and \"big generational companies are getting built,\" which all contribute to a positive sentiment. The discussion also touches on the challenges and considerations in the AI space, such as data privacy and the risk of \"tar pit\" ideas, but these are framed as part of the exciting landscape rather than as deterrents.\n",
            "\n",
            "Overall, the sentiment is one of eagerness and anticipation for the future of technology and entrepreneurship, with a focus on the positive aspects of AI development and the opportunities it presents for founders and researchers.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Great! I've covered different use cases of how to retrieve and generate helpful information relating to longer form content such as a meeting/podcast/lecture."
      ],
      "metadata": {
        "id": "DGTwlabMhaYo"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "uLTtSlz5hlT_"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}